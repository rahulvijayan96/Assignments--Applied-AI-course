{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7eiDWcM_MC3H"
   },
   "source": [
    "# <font color='red'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfe2NTQtLq11"
   },
   "source": [
    "**There will be some functions that start with the word \"grader\" ex: grader_weights(), grader_sigmoid(), grader_logloss() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fk5DSPCLxqT-"
   },
   "source": [
    "<font color='red'> Importing packages</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "42Et8BKIxnsp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpSk3WQBx7TQ"
   },
   "source": [
    "<font color='red'>Creating custom dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "BsMp0oWzx6dv"
   },
   "outputs": [],
   "source": [
    "# please don't change random_state\n",
    "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
    "# make_classification is used to create custom dataset \n",
    "# Please check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "L8W2fg1cyGdX",
    "outputId": "029d4c84-03b2-4143-a04c-34ff49c88890"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 15), (50000,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x99RWCgpqNHw"
   },
   "source": [
    "<font color='red'>Splitting data into train and test </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "0Kh4dBfVyJMP"
   },
   "outputs": [],
   "source": [
    "#please don't change random state\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "gONY1YiDq7jD"
   },
   "outputs": [],
   "source": [
    "# Standardizing the data.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "0DR_YMBsyOci",
    "outputId": "732014d9-1731-4d3f-918f-a9f5255ee149"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37500, 15), (37500,), (12500, 15), (12500,))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BW4OHswfqjHR"
   },
   "source": [
    "# <font color='red' size=5>SGD classifier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "id": "3HpvTwDHyQQy",
    "outputId": "5729f08c-079a-4b17-bf51-f9aeb5abb13b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n",
       "              random_state=15, verbose=2)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha : float\n",
    "# Constant that multiplies the regularization term. \n",
    "\n",
    "# eta0 : double\n",
    "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
    "\n",
    "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
    "clf\n",
    "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "id": "YYaVyQ2lyXcr",
    "outputId": "dc0bf840-b37e-4552-e513-84b64f6c64c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.70, NNZs: 15, Bias: -0.501317, T: 37500, Avg. loss: 0.552526\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.04, NNZs: 15, Bias: -0.752393, T: 75000, Avg. loss: 0.448021\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.26, NNZs: 15, Bias: -0.902742, T: 112500, Avg. loss: 0.415724\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.43, NNZs: 15, Bias: -1.003816, T: 150000, Avg. loss: 0.400895\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.55, NNZs: 15, Bias: -1.076296, T: 187500, Avg. loss: 0.392879\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.65, NNZs: 15, Bias: -1.131077, T: 225000, Avg. loss: 0.388094\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.73, NNZs: 15, Bias: -1.171791, T: 262500, Avg. loss: 0.385077\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.80, NNZs: 15, Bias: -1.203840, T: 300000, Avg. loss: 0.383074\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.86, NNZs: 15, Bias: -1.229563, T: 337500, Avg. loss: 0.381703\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.90, NNZs: 15, Bias: -1.251245, T: 375000, Avg. loss: 0.380763\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.94, NNZs: 15, Bias: -1.269044, T: 412500, Avg. loss: 0.380084\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.98, NNZs: 15, Bias: -1.282485, T: 450000, Avg. loss: 0.379607\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 2.01, NNZs: 15, Bias: -1.294386, T: 487500, Avg. loss: 0.379251\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 2.03, NNZs: 15, Bias: -1.305805, T: 525000, Avg. loss: 0.378992\n",
      "Total training time: 0.23 seconds.\n",
      "Convergence after 14 epochs took 0.23 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n",
       "              random_state=15, verbose=2)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X=X_train, y=y_train) # fitting our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "id": "EAfkVI6GyaRO",
    "outputId": "bc88f920-6531-4106-9b4c-4dabb6d72b47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.89007184,  0.63162363, -0.07594145,  0.63107107, -0.38434375,\n",
       "          0.93235243, -0.89573521, -0.07340522,  0.40591417,  0.4199991 ,\n",
       "          0.24722143,  0.05046199, -0.08877987,  0.54081652,  0.06643888]]),\n",
       " (1, 15),\n",
       " array([-1.30580538]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.coef_.shape, clf.intercept_\n",
    "#clf.coef_ will return the weights\n",
    "#clf.coef_.shape will return the shape of weights\n",
    "#clf.intercept_ will return the intercept term\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-CcGTKgsMrY"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "## <font color='red' size=5> Implement Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1_8bdzitDlM"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "1.  We will be giving you some functions, please write code in that functions only.\n",
    "\n",
    "2.  After every function, we will be giving you expected output, please make sure that you get that output. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zU2Y3-FQuJ3z"
   },
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='blue'>def initialize_weights()</font>)\n",
    "\n",
    "* Create a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
    "\n",
    " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
    "- for each epoch:\n",
    "\n",
    "    - for each batch of data points in train: (keep batch size=1)\n",
    "\n",
    "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='blue'>def gradient_dw()</font>)\n",
    "\n",
    "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
    "\n",
    "        - Calculate the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
    "\n",
    "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
    "\n",
    "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
    "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
    "\n",
    "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
    "    - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
    "    - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
    "        you can stop the training\n",
    "    - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZR_HgjgS_wKu"
   },
   "source": [
    "<font color='blue'>Initialize weights </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "GecwYV9fsKZ9"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(dim):\n",
    "    ''' In this function, we will initialize our weights and bias'''\n",
    "    #initialize the weights to zeros array of (1,dim) dimensions\n",
    "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
    "    #initialize bias to zero\n",
    "    w = np.zeros_like(dim)\n",
    "    b = 0\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "A7I6uWBRsKc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "b = 0\n"
     ]
    }
   ],
   "source": [
    "dim=X_train[0] \n",
    "w,b = initialize_weights(dim)\n",
    "print('w =',(w))\n",
    "print('b =',str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MI5SAjP9ofN"
   },
   "source": [
    "<font color='cyan'>Grader function - 1 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Pv1llH429wG5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X_train[0] \n",
    "w,b = initialize_weights(dim)\n",
    "def grader_weights(w,b):\n",
    "  assert((len(w)==len(dim)) and b==0 and np.sum(w)==0.0)\n",
    "  return True\n",
    "grader_weights(w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QN83oMWy_5rv"
   },
   "source": [
    "<font color='blue'>Compute sigmoid </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPv4NJuxABgs"
   },
   "source": [
    "$sigmoid(z)= 1/(1+exp(-z))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nAfmQF47_Sd6"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    ''' In this function, we will return sigmoid of z'''    \n",
    "    e = 2.718281828459045\n",
    "    sig = 1 / (1 + (e**(-z)))\n",
    "    \n",
    "    return sig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YrGDwg3Ae4m"
   },
   "source": [
    "<font color='cyan'>Grader function - 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "P_JASp_NAfK_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_sigmoid(z):\n",
    "  val=sigmoid(z)\n",
    "  assert(val==0.8807970779778823)\n",
    "  return True\n",
    "grader_sigmoid(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gS7JXbcrBOFF"
   },
   "source": [
    "<font color='blue'> Compute loss </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfEiS22zBVYy"
   },
   "source": [
    "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "VaFDgsp3sKi6"
   },
   "outputs": [],
   "source": [
    "def logloss(y_true,y_pred):\n",
    "    '''In this function, we will compute log loss '''\n",
    "    loss=0\n",
    "    for j in range(len(y_true)):\n",
    "        loss +=  y_true[j]*np.log10(y_pred[j]) +  (1-y_true[j])*np.log10(1-y_pred[j]) \n",
    "    loss = -1*loss/len(y_true)  \n",
    "    print(loss)\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zs1BTXVSClBt"
   },
   "source": [
    "<font color='cyan'>Grader function - 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "LzttjvBFCuQ5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07644900402910389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_logloss(true,pred):\n",
    "  loss=logloss(true,pred)\n",
    "  assert(loss==0.07644900402910389)\n",
    "  return True\n",
    "true=[1,1,0,1,0]\n",
    "pred=[0.9,0.8,0.1,0.8,0.2]\n",
    "grader_logloss(true,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQabIadLCBAB"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to  'w' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTMxiYKaCQgd"
   },
   "source": [
    "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "NMVikyuFsKo5"
   },
   "outputs": [],
   "source": [
    "def gradient_dw(x,y,w,b,alpha,N):\n",
    "    '''In this function, we will compute the gardient w.r.to w '''\n",
    "\n",
    "    dw = (x*(y - sigmoid(np.dot(w,x)+b) - ((alpha*w)/N) ))\n",
    "\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUFLNqL_GER9"
   },
   "source": [
    "<font color='cyan'>Grader function - 4 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "WI3xD8ctGEnJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_dw(x,y,w,b,alpha,N):\n",
    "  grad_dw=gradient_dw(x,y,w,b,alpha,N)\n",
    "  assert(np.sum(grad_dw)==2.613689585)\n",
    "  return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w,grad_b=initialize_weights(grad_x)\n",
    "alpha=0.0001\n",
    "N=len(X_train)\n",
    "\n",
    "grader_dw(grad_x,grad_y,grad_w,grad_b,alpha,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LE8g84_GI62n"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to 'b' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHvTYZzZJJ_N"
   },
   "source": [
    "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "0nUf2ft4EZp8"
   },
   "outputs": [],
   "source": [
    " def gradient_db(x,y,w,b):\n",
    "        \n",
    "    db = (y - sigmoid(np.dot(w,x)+b))\n",
    "    return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbcBzufVG6qk"
   },
   "source": [
    "<font color='cyan'>Grader function - 5 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "TfFDKmscG5qZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_db(x,y,w,b):\n",
    "  grad_db=gradient_db(x,y,w,b)\n",
    "  assert(grad_db==-0.5)\n",
    "  return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w,grad_b=initialize_weights(grad_x)\n",
    "alpha=0.0001\n",
    "N=len(X_train)\n",
    "grader_db(grad_x,grad_y,grad_w,grad_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCK0jY_EOvyU"
   },
   "source": [
    "<font color='blue'> Implementing logistic regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "dmAdc5ejEZ25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37500,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n",
    "    ''' In this function, we will implement logistic regression'''\n",
    "    #Here eta0 is learning rate\n",
    "    # initalize the weights (call the initialize_weights(X_train[0]) function)\n",
    "    \n",
    "    weight,bias = initialize_weights(X_train[0])\n",
    "    train_loss=[]\n",
    "    test_loss=[]\n",
    "\n",
    "    for epoch in range(epochs):        \n",
    "\n",
    "        y_pred_train=[]\n",
    "        y_pred_test=[]\n",
    "        for m in range(len(X_train)):             \n",
    "            \n",
    "            grad_w = gradient_dw(X_train[m],y_train[m],weight,bias,alpha,N)\n",
    "            grad_b = gradient_db(X_train[m],y_train[m],weight,bias)\n",
    "\n",
    "            weight += eta0*grad_w\n",
    "            bias += eta0*grad_b\n",
    "            \n",
    "        for n in range(len(X_train)):\n",
    "            y_pred_train.append(sigmoid(np.dot(weight,X_train[n])+bias))\n",
    "\n",
    "        loss_train = logloss(y_train,y_pred_train)\n",
    "        train_loss.append(loss_train)\n",
    "        \n",
    "        for o in range(len(X_test)):\n",
    "            y_pred_test.append(sigmoid(np.dot(weight,X_test[o])+bias))\n",
    "\n",
    "        loss_test = logloss(y_test,y_pred_test)\n",
    "        test_loss.append(loss_test)\n",
    "\n",
    "    return weight,bias,train_loss,test_loss\n",
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "sUquz7LFEZ6E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20729781768555863\n",
      "0.20722219765639835\n",
      "0.1855621011421076\n",
      "0.18565259407762202\n",
      "0.17659652051133365\n",
      "0.17682567687044423\n",
      "0.1720128945783102\n",
      "0.17235324810702143\n",
      "0.16938000845565493\n",
      "0.16981009801866534\n",
      "0.16775336534502722\n",
      "0.16825663459379128\n",
      "0.16669776257314284\n",
      "0.167261288529954\n",
      "0.1659883746149783\n",
      "0.16660192950797564\n",
      "0.16549918190509713\n",
      "0.1661545708821791\n",
      "0.16515513910536045\n",
      "0.16584572638431586\n",
      "0.16490944263438445\n",
      "0.16562980512109723\n",
      "0.1647318308366498\n",
      "0.16547750011239434\n",
      "0.16460216936736333\n",
      "0.1653694365707766\n",
      "0.1645067496369603\n",
      "0.16529251605486997\n"
     ]
    }
   ],
   "source": [
    "alpha=0.0001\n",
    "eta0=0.0001\n",
    "N=len(X_train)\n",
    "epochs=14\n",
    "w,b,train_loss,test_loss=train(X_train,y_train,X_test,y_test,epochs,alpha,eta0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4Zf_wPARlwY"
   },
   "source": [
    "<font color='red'>Goal of assignment</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3eF_VSPSH2z"
   },
   "source": [
    "Compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "nx8Rs9rfEZ1R"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-4.75142659e-03,  7.60248362e-03,  1.85101563e-03,\n",
       "          6.50616171e-05,  1.54496319e-03,  2.34090261e-03,\n",
       "         -9.09959192e-04,  2.16124271e-03,  5.21961272e-03,\n",
       "         -4.49832519e-03,  1.23629737e-03,  2.54417911e-03,\n",
       "          1.74962265e-03, -1.28754200e-03,  1.05365292e-03]]),\n",
       " array([0.0027995]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
    "w-clf.coef_, b-clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "230YbSgNSUrQ"
   },
   "source": [
    "<font color='blue'>Plot epoch number vs train , test loss </font>\n",
    "\n",
    "* epoch number on X-axis\n",
    "* loss on Y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "1O6GrRt7UeCJ"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('LOSS vs EPOCH')\n",
    "plt.plot(train_loss)\n",
    "plt.plot(test_loss)\n",
    "plt.legend(['train','test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN AND TEST ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "id": "FUN8puFoEZtU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN ACCURACY :  0.9505866666666667\n",
      "TEST ACCURACY :  0.9476\n"
     ]
    }
   ],
   "source": [
    "def pred(w,b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        z=np.dot(w,X[i])+b\n",
    "        if sigmoid(z) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
    "            predict.append(1)\n",
    "        else:\n",
    "            predict.append(0)\n",
    "    return np.array(predict)\n",
    "print(\"TRAIN ACCURACY : \",1-np.sum(y_train - pred(w,b,X_train))/len(X_train))\n",
    "print(\"TEST ACCURACY : \",1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
